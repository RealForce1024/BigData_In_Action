<!DOCTYPE html><html><head><title>day06</title><meta charset='utf-8'><link href='https://dn-maxiang.qbox.me/res-min/themes/marxico.css' rel='stylesheet'><style></style></head><body><div id='preview-contents' class='note-content'>
                        <div id="wmd-preview" class="preview-content"></div>
                    <div id="wmd-preview-section-61687" class="wmd-preview-section preview-content">

</div><div id="wmd-preview-section-61780" class="wmd-preview-section preview-content">

<h1 id="day06">day06</h1>

<p></p>

<hr>

<div><div class="toc"><div class="toc">
<ul>
<li><a href="#day06">day06</a><ul>
<li><a href="#回顾">回顾</a></li>
<li><a href="#hadoop">Hadoop</a><ul>
<li><a href="#hadoop的三大核心组件">hadoop的三大核心组件</a></li>
<li><a href="#hadoop的背景">Hadoop的背景</a></li>
<li><a href="#应用场景">应用场景</a></li>
<li><a href="#就业情况分析">就业情况分析</a></li>
</ul>
</li>
<li><a href="#hadoop应用流程-概述">hadoop应用流程 概述</a><ul>
<li><a href="#网站或app点击流日志数据挖掘系统">网站或APP点击流日志数据挖掘系统</a></li>
<li><a href="#数据采集">数据采集</a></li>
<li><a href="#流程解析离线分析">流程解析（离线分析）</a></li>
<li><a href="#推荐系统架构模型">推荐系统架构模型</a></li>
<li><a href="#实时推荐">实时推荐</a></li>
<li><a href="#项目技术架构图">项目技术架构图</a></li>
</ul>
</li>
<li><a href="#前期准备">前期准备</a></li>
<li><a href="#安装集群">安装集群</a><ul>
<li><a href="#官网下载hadoop">官网下载hadoop</a></li>
<li><a href="#安装">安装</a><ul>
<li><a href="#统一建立用户">统一建立用户</a></li>
<li><a href="#重新配置securecrt-登录信息">重新配置secureCrt 登录信息</a></li>
<li><a href="#环境准备">环境准备</a></li>
</ul>
</li>
<li><a href="#hadoop集群节点配置">hadoop集群节点配置</a><ul>
<li><a href="#hadoop运行时环境变量配置">hadoop运行时环境变量配置</a></li>
</ul>
</li>
<li><a href="#分发hadoop到节点服务器">分发hadoop到节点服务器</a></li>
<li><a href="#hdfs使用前先格式化">hdfs使用前先格式化</a><ul>
<li><a href="#格式化">格式化</a></li>
<li><a href="#成功标志">成功标志</a></li>
<li><a href="#子节点并未配启动时增加一台就认识一台">子节点并未配，启动时增加一台就认识一台</a></li>
</ul>
</li>
<li><a href="#常见错误">常见错误</a></li>
</ul>
</li>
<li><a href="#hadoop的使用">hadoop的使用</a><ul>
<li><a href="#hdfs">hdfs</a></li>
<li><a href="#实现作业">实现作业</a></li>
<li><a href="#mr-yarn上">mr (yarn上)</a></li>
<li><a href="#worldcount案例体验">worldcount案例体验</a></li>
<li><a href="#hdfs的常用命令">hdfs的常用命令</a></li>
</ul>
</li>
<li><a href="#hdfs-java-api">HDFS Java api</a><ul>
<li><a href="#代码案例上传文件">代码案例：上传文件</a><ul>
<li><a href="#代码">代码</a></li>
<li><a href="#问题解决本地环境问题空指针与用户权限问题">问题解决（本地环境问题空指针与用户权限问题）</a><ul>
<li><a href="#发生空指针异常">发生空指针异常</a></li>
<li><a href="#windows上配置hadoop环境变量">windows上配置hadoop环境变量</a></li>
<li><a href="#windows-上编译hadoop-bin目录-lib替换">windows 上编译hadoop bin目录 lib替换</a></li>
<li><a href="#权限不足">权限不足</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
</div>

<p><a href="http://123.56.240.191/bigdata.html" target="_blank">目录</a></p></div><div id="wmd-preview-section-61689" class="wmd-preview-section preview-content">

<h2 id="回顾">回顾</h2>

<p>jvm方面的提高 多看些书籍，最新的jvm已经有了些变化。 <br>
深入理解Java虚拟机 <br>
jvm性能。。实战</p>

<p>NIO与io的差别再次巩固 <br>
缓存的复制少些 <br>
案例 传统io写文件到另一台机器   传统io更快 <br>
nio阻塞少些，并发量更大，适合服务器端</p>

<p>AIO完全是异步的，selector不要了… </p>

<hr>

</div><div id="wmd-preview-section-61690" class="wmd-preview-section preview-content">

<h2 id="hadoop">Hadoop</h2>

<p>hdp spark（akka）  <br>
现在都转为 netty <br>
dubbo也是netty的底层 </p>

<p>scala 快学scala -&gt; scala编程指南</p>

<p>认识性的介绍 组件  搭建hadoop集群</p>

<ol><li rel="1">开源的软件平台，类似中间件</li>
<li rel="2">服务器集群 ，根据用户自定义的业务逻辑，对海量数据进行处理运算。</li>
<li rel="3">昨天作业思路讲解  分布式统计单词 <br>
<ol>
<li rel="4">[socket,ioutils.copy(in,out)]</li>
<li rel="5">java -jar task.jar /dir</li>
<li rel="6">jar -cp cn…Task  task.jar /dir  -Xmx=2000m -Xms=2000m</li>
<li rel="7">exec(“cmd”)</li>
<li rel="8">未汇总，失败机制等待。。。很呆萌啊……如此简单的业务，写得如此多….</li></ol></li>
</ol>

</div><div id="wmd-preview-section-61691" class="wmd-preview-section preview-content">

<h3 id="hadoop的三大核心组件">hadoop的三大核心组件</h3>

<ol start="10"><li rel="10"><strong>hdfs</strong>  大文件如何切块? hdfs的机制 （分布式文件系统） </li>
<li rel="11"><strong>YARN</strong> （运算资源调度） 集群可以跑不同用户不同业务的任务，内存，io，cpu等硬件资源的分配管理 （让更多的程序并发的跑是我们的需求） [worker(node manager)-&gt;yarn  master(<strong>resource manager)</strong>]   </li>
<li rel="12"><strong>mapreduce</strong> (分布式运算框架，编程模板框架) （大体预览） <br>
<ol>
<li rel="13">各台机器<strong>局部结果</strong>（个做个的，局部并发执行） <strong>map task</strong> </li>
<li rel="14"><strong>汇总结果</strong> <strong>reduce task</strong></li>
<li rel="15"><strong>dirver</strong> task的发送等 </li></ol></li>
<li rel="16">广义上来说 hadoop是个大的生态圈  Hadoop Ecosystem Map 。。(老图) <br>
<ol>
<li rel="17"><strong>hbase</strong> 基于hadoop之上的数据库</li>
<li rel="18"><strong>hive</strong> 支持sql的数据分析语言 （Java写逻辑臃肿，用sql的方式 就很easy，hive作为中间件转换，写sql较多……,hive里面有很多的sql转mr的程序….dba就开始假装懂hadoop了….一样假装玩的666.。。。）</li>
<li rel="19"><strong>zookeeper</strong>  其他组件都是分布式的，都面临着协调问题…..并没有真正的管理，只是拿铲子…协调…铲…</li>
<li rel="20">10  oozie cascading  八爪鱼 乌贼（较重） 工作流 我们讲skamen 阿兹卡玛..。。(简单)</li>
<li rel="21">mahout  训象师  机器学习算法  k-means… 属性  分类  维度 二维度平面距离 （三维）空间距离  四维。。。。。 运算量很大..单机版速度会很慢，分布式并发运算速度就很快，写成该种模型 mahout 重新写一遍,,统统写成了mr版本…(重点是数据，如何用，使用场景，业务场景) 天生门槛 功底 大部分场景是定制的…推荐系统..协同过滤算法…需要改造定制..</li>
<li rel="22">flume  分布式数据采集  </li>
<li rel="23">sqoop  数据抽取迁移工具</li>
<li rel="24">等等…….</li></ol></li>
</ol>

</div><div id="wmd-preview-section-61692" class="wmd-preview-section preview-content">

<h3 id="hadoop的背景">Hadoop的背景</h3>

<ol start="26"><li rel="26">最早起源于nutch (google baidu) ， 严重的 可拓展性问题（比如数十亿网页的存储与索引问题）</li>
<li rel="27">GFS 、MapReduce 、数据库BIGTable</li>
<li rel="28">nutch 也遇到了上面的 问题，借鉴了谷歌三大论文，实现了hdf mr 。另hive ，三者都有了对应解决方案</li>
<li rel="29">pass层 并不等同于云啥的….概念 是 玄</li>
</ol>

</div><div id="wmd-preview-section-61693" class="wmd-preview-section preview-content">

<h3 id="应用场景">应用场景</h3>

<ol start="31"><li rel="31">阿里 云梯</li>
<li rel="32">数据分析 用户画像  用户标签  分析数据</li>
<li rel="33">点击流日志数据挖掘</li>
</ol>

</div><div id="wmd-preview-section-61694" class="wmd-preview-section preview-content">

<h3 id="就业情况分析">就业情况分析</h3>

<ol start="35"><li rel="35">十三五规划</li>
<li rel="36">物联网待爆发</li>
<li rel="36">招聘网 大数据… 做你没做过的磨炼能力….</li>
<li rel="37">hadoop文件分析常用  图像分析 </li>
<li rel="38">分布式架构经验 原理 不会过时</li>
</ol>

<hr>

</div><div id="wmd-preview-section-61695" class="wmd-preview-section preview-content">

<h2 id="hadoop应用流程-概述">hadoop应用流程 概述</h2>

</div><div id="wmd-preview-section-61696" class="wmd-preview-section preview-content">

<h3 id="网站或app点击流日志数据挖掘系统">网站或APP点击流日志数据挖掘系统</h3>

<p><strong>cnzz 数据专家</strong> <br>
mafengwo.cn  其页面中嵌入了cnzz的脚本  url转码查看 tool.chinaz.com/tool  <br>
页面的热点图</p>

<p>jd  log.gif js生成1像素图片 ..后台请求</p>

<p>分析用户的浏览行为   运营 推荐等等 </p>

<p>分析转化率 踩踩你喜欢  促销页面 等等</p>

</div><div id="wmd-preview-section-61697" class="wmd-preview-section preview-content">

<h3 id="数据采集">数据采集</h3>

<p>埋点 js 传入到后台请求 日志收集系统</p>

</div><div id="wmd-preview-section-61698" class="wmd-preview-section preview-content">

<h3 id="流程解析离线分析">流程解析（离线分析）</h3>

<p>与典型的BI系统极其类似 <br>
<strong>数据采集–数据预处理（hadoop mr）–导入hive仓库（文件映射成表，写sql…页面转化，僵尸用户，业务指标决定…）–etl – 报表统计—到处到mysql等数据库—数据可视化（开源项目Echarts highcharts或自己写web工具）</strong> <br>
用户画像 推荐 行为分析</p>

</div><div id="wmd-preview-section-61699" class="wmd-preview-section preview-content">

<h3 id="推荐系统架构模型">推荐系统架构模型</h3>

<p><strong>大量历史数据</strong>的分析 <br>
咖啡 – 咖啡杯 –咖啡豆–</p>

<p>页面（js）—后台（tomcat…jboss..）集群—log 文件(log.info )—flume配置目标hdfs— 汇聚hdfs(原始日志 集群) —预处理 (hadoop mr) –hive(hdfs本质还是在hdfs中，映射成表 )—etl（在hive中写sql）—雀巢 咖啡杯 咖啡伴侣 | spark 深入 深入Java / 用户画像 (屌丝….   小鲜肉…  女神 …) —-导出到推荐业务系统数据库— 看了又看、其他人也买过 猜你喜欢、热门关注 达人选购 …—经过后台修正或筛选（一些不合理的推荐、强行推荐（雾霾天强推口罩等））</p>

</div><div id="wmd-preview-section-61700" class="wmd-preview-section preview-content">

<h3 id="实时推荐">实时推荐</h3>

<p>热卖 离线的历史数据来不及更新</p>

<p>今天的数据拿过来，不到hdfs，看到kafka（支持实时的快速读写）集群中——-一条线 直接到storm（实时的快速分布式计算 ）/ spark Streaming  实时处理 —-另一条线放入hdfs中—放入msyql数据库 <br>
sql是统计方式的  hive-sql 基于sql统计模型结果 <br>
mahout机器学习方式  mr—-mahout 、mlib 机器学习模型</p>

</div><div id="wmd-preview-section-61701" class="wmd-preview-section preview-content">

<h3 id="项目技术架构图">项目技术架构图</h3>

<p>大局观 很重要</p>

</div><div id="wmd-preview-section-61702" class="wmd-preview-section preview-content">

<h2 id="前期准备">前期准备</h2>

<p>haddop  <br>
    hdfs集群 <br>
    yarn集群 <br>
起步建议3、4台机器 弹性伸缩的 1-&gt; 雅虎…排序比赛….</p>

<p>hdfs nameNode master port:9000（针对客户端访问） <br>
        dataNode  slave  <br>
yarn  放在那里好点？ 负责为mr程序分配运算硬件资源，数据在程序中是最好的，及运算移动到数据端 ，即yarn放在dataNode中最为合适（建议不要分开，减少通信损耗，节省机器11:35-11:36 真实情况分开？）。 node manager <br>
node resource </p>

</div><div id="wmd-preview-section-61703" class="wmd-preview-section preview-content">

<h2 id="安装集群">安装集群</h2>

<p>4台机器准备 <br>
512m有些少</p>

</div><div id="wmd-preview-section-61704" class="wmd-preview-section preview-content">

<h3 id="官网下载hadoop">官网下载hadoop</h3>

<p><a href="http://hadoop.apache.org" target="_blank">官网</a> <br>
hadoop common （rpc 所在其中） <br>
ambari 页面安装管理工具 图形化界面管理 ..  实现cdh的商业效果 <br>
cloudrea cdh 商业公司 发布商业版hadoop </p>

<p><strong>版本</strong> <br>
1.2.X <br>
<strong>2.2.0</strong> 目前使用较多 <br>
current  2.7.2  <br>
<strong>documents</strong> <br>
 <strong>tutorial</strong>  <br>
REST-api 效率低，我们使用不多…看业务情景 <br>
<strong>tools</strong> <br>
<em>* reference api*</em>  <strong>我们作为hadoop用户</strong>，关注用户该关注的api（<strong>我们关注用户接口</strong>） <br>
<strong>Configuration</strong> 这里很重要  core  map hdfs  yarn properties  <br>
hadoop配置参数说明大全.doc…速查即可</p>

</div><div id="wmd-preview-section-61705" class="wmd-preview-section preview-content">

<h3 id="安装">安装</h3>

</div><div id="wmd-preview-section-61706" class="wmd-preview-section preview-content">

<h4 id="统一建立用户">统一建立用户</h4>

<p>send to all <br>
useradd hadoop <br>
passwd hadoop  hadoop</p>

</div><div id="wmd-preview-section-61707" class="wmd-preview-section preview-content">

<h4 id="重新配置securecrt-登录信息">重新配置secureCrt 登录信息</h4>

</div><div id="wmd-preview-section-61708" class="wmd-preview-section preview-content">

<h4 id="环境准备">环境准备</h4>

<p>Java 环境 <br>
echo $Java_Home <br>
sudo scp -r /usr/local/jdk…  mini4:/usr/local/  <br>
su  root  或者 配置 sudoers.</p>

<p>保证java能运行 bin/java <br>
vi /etc/profile <br>
source profile 注意在hadoop用户下</p>

<p>vi /etc/sudoers <br>
yyp <br>
hadoop  All = (All)  all .. <br>
wq!</p>

<p>sudo hostname …</p>

<p>防火墙关掉 <br>
su root <br>
service iptables stop <br>
chkconfig iptables off //永久配置 <br>
免密登录</p>

<hr>

<p>回顾 <br>
上午 hadoop的认识 使用场景 推荐系统的工作机制 数据处理流程理解 </p>

<p>jdk 防火墙关闭 最好使用普通用户来安装 <br>
配置免密登录</p>

<p>2.6.4版本  上课使用 <br>
2.7.2 <br>
archive.apache.org // <br>
与本地系统的api</p>

<p>tar.gz <br>
src.tar.gz //需要编译 安装c++  解压linux maven   参见《hadoop编译.docx》 <br>
中央仓库 <br>
search.maven.org <br>
maven.oschina.net <br>
rz ..传送的比sftp稍慢</p>

<p>mkdir apps <br>
ll <br>
tar -zxvf cent…tar.gz -C apps/ <br>
cd hadoop-2.6.4</p>

<ul><li>bin </li>
<li>sbin 启动时一些命令</li>
<li>etc 配置文件</li>
<li>native 本地库</li>
<li>share 依赖的jar与 文档 -doc {common hdfs mapreduce…}  -hadoop *.jar lib/</li>
<li>include 依赖</li>
</ul>

</div><div id="wmd-preview-section-61709" class="wmd-preview-section preview-content">

<h3 id="hadoop集群节点配置">hadoop集群节点配置</h3>

</div><div id="wmd-preview-section-61710" class="wmd-preview-section preview-content">

<h4 id="hadoop运行时环境变量配置">hadoop运行时环境变量配置</h4>

<p>cd /etc   </p>

<ul><li>hadoop-env.sh  运行时的环境变量</li>
<li>echo $JAVA_HOME </li>
<li><strong>vi hadoop-env.sh</strong> <br>


<blockquote>
  <p>export JAVA_HOME=/usr/local/jdk…. <br>
  hadoop的运行时配置</p></blockquote></li>
  </ul> <br>
  其实配置在哪里都可以，分层便于管理查看
  
  <ul><li>core-site.xml  公共参数配置</li>
  <li>hdfs-site.xml</li>
  <li>mapred-site.xml.template</li>
  <li>yarn-site.xml</li>
  </ul>
  
  <p>vi core-site.xml <br>
  &lt;configuration  .....   官网 configuration  <br>
  &lt;property <br>
  &lt;name  <strong>fs.defultFS</strong> 文件系统的默认文件系统 存储于运算系统是解耦的 gfs tfs nfs file:/// <br>
  &lt;value  hdfs://mini:9000 //uri  客户端访问hdfs nameNode地址 <strong>hdfs://${nameNode}:port</strong>  //master node <br>
  


注意以下是伪格式
2 工作进程的数据目录
&lt;property
name:hadoop.tmp.dir
value :/home/haddop/hapdata


vi hdfs-site.xml
可以不配，都有默认值 。 假装配置一下
name dfs.blocksize// 配置块的大小 |dfs.replication 
value 2 //存成两份 down一台还是可以取出数据 默认为3

vi mapred-site.xml.template //如果不写 默认 value 为local 单机版 模拟的小程序
name mapreduce.framework.name //mr运行的平台
value yarn   
mv   .templae  …xml

vi yarn.site.xml
name yarn.resourcemanager.hostname
value mini1

name yarn.nodemanager.aux-services
value mapreduce_shuffle   //reducer获取数据的方式







</p></div><div id="wmd-preview-section-61711" class="wmd-preview-section preview-content">



<h3 id="分发hadoop到节点服务器">分发hadoop到节点服务器</h3>

将app文件夹分发
scp -r apps mini2:/home/hadoop
scp -r apps mini3:/home/hadoop
scp -r apps mini4:/home/hadoop







</div><div id="wmd-preview-section-61712" class="wmd-preview-section preview-content">



<h3 id="hdfs使用前先格式化">hdfs使用前先格式化</h3>

非底层文件系统，架构在linux文件系统之上。 生成些数据目录

配置环境变量
sudo vi /etc/profile
export HADOOP_HOME = 
export PATH=<span class="" rel="b1890c3074560a992746043690abdb4c"><span class="MathJax_SVG" id="MathJax-Element-5-Frame" role="textbox" aria-readonly="true" style="font-size: 100%; display: inline-block;"><span><img type="image/png" width="62" height="14" longdesc="__SVG__undefined" src="data:image/png;base64,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" style="margin-top:0;margin-bottom:0;"></span></span></span>HADOOP_HOME/bin/ .. sbin

sudo scp /etc/profile mini2:/etc/
sudo scp /etc/profile mini3:/etc/
sudo scp /etc/profile mini4:/etc/
sudo scp /etc/profile mini5:/etc/

source /etc/profile







</div><div id="wmd-preview-section-61713" class="wmd-preview-section preview-content">



<h4 id="格式化">格式化</h4>

hadoop namenode -format   //格式化 生成出事目录 类似–账本






</div><div id="wmd-preview-section-61714" class="wmd-preview-section preview-content">



<h4 id="成功标志">成功标志</h4>

storage direcorty   hdp/data/dfs/name has been successfully formatted ..

cd  ../dfs/name/current   看到一些生成文件

启动
/sbin
hadoop-daemon.sh  start namenode  //hadoop 启动
jps 查看
那datanode呢？
通过web访问看下
http://ip:/50070/
dfs capcity… 
此时发现datanode是没有的
启动datanode mini2  mini3   mini4
hadoop-daemon.sh start datanode
jps
此时有联系么？ 
live node 此时是有的 并且 capacity 也开始有值了 

datanode 与namenode是如何握手的
当时的配置文件是一样配置的 通过配置文件的namenode知道的

启动发下没哟，也没报错
看日志 loggin…
看 .log文件 而非 .out







</div><div id="wmd-preview-section-61715" class="wmd-preview-section preview-content">



<h4 id="子节点并未配启动时增加一台就认识一台">子节点并未配，启动时增加一台就认识一台</h4>

**太特么的麻烦了，搞个脚本吧**
hadoop-daemon.sh stop  datanode

vi startall.sh // 其实是有的
start-dfs.sh
start-yarn.sh
…
/etc/hadoop
slaves // 给自动化启动脚本使用的  ， 没配置一样可以启用
vi slaves 
localhost  //本地启动namenode
mini2
mini3
mini4

**start-dfs.sh  如何启动其他机器**
ssh mini2 haddop-daemon.sh start datanode 输密码

start-dfs.sh  密码…

自动给启动了 secondary namenode 0.0.0.0
自动化脚本 我们还需要配置一个免密登录 
1-2-3-4-1
看在哪里启动脚本 所以一般在namenode 山该配置下
cat /etc/hosts
ssh-copy-id mini1
ssh-copy-id mini2
ssh-copy-id mini3
ssh-copy-id mini4

ssh mini4 测试

自动化脚本将所有的停止
stop-dfs.sh  //不建议使用-all 啥的，不容易定位错误
stop-dfs.sh  此时就不用再输入密码了 关闭其他datanode

start-all.sh  // but deprecated ….  suggest hdfs.sh  yarn.sh 

配置secondayr.http.address 指定seconddary所在的机器  hdfs.site.xml

namenode   ssh mini1
resourcemanager  // 本地起， 不需要通过ssh的方式 15：27分

<hr>

层层剥离…
start.sh 啥的与haddop是无关的，要理解启动机制 
动态扩容上线（启动一台新机器） 、下线（数据是分散的）
加入只要一台机器，配置三个副本呢？ 与不会有三个副本







</div><div id="wmd-preview-section-61716" class="wmd-preview-section preview-content">



<h3 id="常见错误">常见错误</h3>

<ul><li>权限不统一问题 <br>
root 用户启动 下 登录到hadoop 启动不来 ,,权限是变为root用户的了…. <br>
切记 是在哪个用户下 。 <br>
尽量不用su root <br>
sudo 方式..</li>
<li>配置文件的错误</li>
<li>ssh没有配置好</li>
<li>unknown host （统统用主机名 拷贝分发文件即可）</li>
</ul>

</div><div id="wmd-preview-section-61717" class="wmd-preview-section preview-content">

<h2 id="hadoop的使用">hadoop的使用</h2>

</div><div id="wmd-preview-section-61718" class="wmd-preview-section preview-content">

<h3 id="hdfs">hdfs</h3>

<p>web 页面可以看到概览 <br>
传文件  utilities  浏览文件系统 <br>
/ hdfs 自己的抽象的文件系统根目录  tmp..hdpdata- dfs-data(datanode的工作目录) 很深的，要到底…. finalized….. 直接丢文件 人家不认识的 太暴力了</p>

<p>我们使用客户端工具 web是没有的，命令行客户端会有的。 <br>
source /etc/profile <br>
在hdp 安装包中 bin/hdfs  或haddop</p>

<blockquote>
  <p>hadoop fs  -ls /  很慢.. <br>
  hdoop fs -ls hdfs://minin:9000/ </p>
</blockquote>

<p><strong>道&gt;术</strong> <br>
echo “helloworld” &gt; cls_wm.avi <br>
ll <br>
<strong>上传</strong> <br>
hadoop fs -put cls_wm.avi /  //上传文件到fs /目录 <br>
到web上即可查看到 <br>
<strong>hadoop fs -ls /</strong> <br>
hdfs 谁上传的就是谁的用户 并不严格 可以修改用户 <br>
<strong>查看</strong> mini4 <br>
hadoop fs -cat /….avi <br>
被存到哪里了？ 数据在哪里  先就近存放  hdpdata cd …….. blk_…..   blk_1112323_23.meta </p>

<p>另外机器呢？ <br>
mini3上也有</p>

<p>mini2呢？ 没有 ，赔了俩副本</p>

<p>what ..blk 文件 <br>
默认128m才开始切割 <br>
cat blk 小文件没有切</p>

<p>测试 hadoop*.tar.gz</p>

<p>haddop fs -put cent…tar.gz / <br>
cat *26 &gt;&gt; tmp.file <br>
cat *27 &gt;&gt; tmp.file  <br>
手动拼接文件  <br>
tar -zxvf tmp.file . <br>
<strong>hdfs 切割文件</strong>通过上面的实例 可以很清晰的理解</p>

<p>hadoop fs -get /ce…tar.gz  //给完整文件 ，而非切割文件 <br>
<strong>在客户端中拼接的</strong></p>

</div><div id="wmd-preview-section-61719" class="wmd-preview-section preview-content">

<h3 id="实现作业">实现作业</h3>

<p>模拟实现 dfs  datanode（本质sockeServer）  <br>
客户端 有个文件  fileInputStream <br>
socket = socket(datanode ,port) <br>
socket.getoutputStream <br>
while((b = in.read!)=-1){ <br>
count&lt;134217728 <br>
out.write(b) <br>
}</p>

<p>128m后 <br>
再new socket 挑选另外一台机器 <br>
sokcet  in - -&gt; out  –&gt; datanode2 <br>
sokcet.in  <br>
fileout .. <br>
加强 sokcet io hdfs的理解 <br>
该案例其实是少了namenode的。（客户端需要先找到namenode 再找datanode），健壮性 容错性…自己打磨…</p>

</div><div id="wmd-preview-section-61720" class="wmd-preview-section preview-content">

<h3 id="mr-yarn上">mr (yarn上)</h3>

<p>我们可以先看 hadoop自带的demo <br>
worldcount <br>
准备些数据 <br>
vi a.txt <br>
hello world  <br>
hello baby <br>
heloo wangboyi <br>
hello wutenggaoshu <br>
cp a.txt b.txt  <br>
俩文件做单词统计  <br>
放到hdfs中 <br>
hadoop fs -mkdir -p /worldcoutn/input   [-p 批量建立目录] <br>
web系统查看能看到 <br>
hadoop fs -put a.txt b.txt /worldoucnt/input </p>

</div><div id="wmd-preview-section-61721" class="wmd-preview-section preview-content">

<h3 id="worldcount案例体验">worldcount案例体验</h3>

<p>cd  apps/haddooop/share/mapreduce/hadoop-mr-example.jar <br>
<strong>hadoop jar hadoop-mr-example worldcount(主类) /worldcount/input/ /worldcount/output(不要存在)</strong></p>

<p>结果 web中快速查看  /worldcoutn/output <br>
_success <br>
<em>part</em>…. <br>
hadoop fs -cat /worldout/output/part-r-00000  敲得多 你来讲课 也记得。。。</p>

</div><div id="wmd-preview-section-61722" class="wmd-preview-section preview-content">

<h3 id="hdfs的常用命令">hdfs的常用命令</h3>

<p>与linux命令基本一样 <br>
hadoop fs 列出所有的命令 <br>
put get mkdir chmod </p>

<ul><li>ls</li>
<li>mkdir</li>
<li>moveFromLocal a.txt /world/input本地文件移动到hdfs中  put是拷贝 </li>
<li>moveToLocal 从hdfs剪切粘贴到本地</li>
<li>appendToFile  本地的文件追加到hdfs中已经存在的文件中</li>
<li>cat  显示文件内容  文件很大的时候使用 more | tail</li>
<li>tail </li>
<li>text 类似 cat 以字符的形式显示  </li>
<li>乱码 exit 再来…</li>
<li>chgrp  改组</li>
<li>chmod 改权限</li>
<li>chown 可改用户也可该组  hdfs是无用户的概念的….hdfs是弱的权限设置</li>
<li>cp hdfs路径文件路径间的拷贝</li>
<li>getmerge  下载合并文件 16:31分很…. </li>
<li>rm -r(递归)</li>
<li>rmdir 删除空目录</li>
<li>df 统计文件系统的空间大小 -h / </li>
<li>du 统计一个文件夹的大小 -s (汇总) -h(带单位) <br>
<ul>
<li>hadoop fs -df -h -s -h /*  统计到了linux 上 貌似bug</li>
<li>hadoop fs -df -h -s -h hdfs://mini1:9000/* </li></ul></li>
<li>count 统计一个目录下的文件节点数</li>
<li>setrep 设置hdfs文件的副本数量   文件夹数描述 元数据 没啥大小  -setrep 3 /a.txt <br>
web 页面上看看 replication 上确实是3份 <br>
那如果10个呢？ 只有3个的datanode节点 ，那到底实际上是否有10个呢？ <br>
将所有文件都情况，执行查看下 其实是没有的， <br>
10是元数据，加了机器会多复制出来，现在机器是没有那能里的 <br>
<strong>replication 不是真实的，是份元数据 只是记录namenode的元数据中，得看datanode的实际数量</strong></li>
</ul>

<hr>

<p>基础要打牢，否则后面将会云里雾里.</p>

</div><div id="wmd-preview-section-61723" class="wmd-preview-section preview-content">

<h2 id="hdfs-java-api">HDFS Java api</h2>

<p>在win中解压 hadoop..tar.gz  shell haoop -&gt; jar  手动导包 <br>
maven hadoop-client 即可</p>

<p>新建Java工程 <br>
shizhan03_hadoop  lib  包 或建立 本地的包链接 add library user library…. <br>
hdfsjar library  <br>
  —  common jar <br>
lib-依赖 全选  <br>
 hdfs 核心</p>

<p>com.fqc.bigdata.hdfs; <br>
 HdfsClientDemo.java</p>

</div><div id="wmd-preview-section-61724" class="wmd-preview-section preview-content">

<h3 id="代码案例上传文件">代码案例：上传文件</h3>

</div><div id="wmd-preview-section-61725" class="wmd-preview-section preview-content">

<h4 id="代码">代码</h4>

</div><div id="wmd-preview-section-61726" class="wmd-preview-section preview-content">

<pre class="prettyprint hljs-dark"><code class="hljs aspectj"> Filesystem fs = <span class="hljs-keyword">null</span><br>\<span class="hljs-annotation">@Before</span><br><span class="hljs-keyword">public</span> <span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">init</span><span class="hljs-params">()</span></span>{<br>    configuration conf  =   <span class="hljs-keyword">new</span> Configuration();<span class="hljs-comment">// 默认是本地的文件系统配置</span><br>    conf.set(<span class="hljs-string">"fs.defaultFS"</span>,<span class="hljs-string">"hdfs://mini1:9000"</span>); <span class="hljs-comment">//默认不配的话是 localFileSystem</span><br>    <span class="hljs-comment">//获取文件系统操作的客户端实例对象</span><br> fs =   FileSystem.get(conf);  <span class="hljs-comment">//构造的是 DistirutedFileSystem  //ctrl+t 看下fileSystem的实现类【注意viewFileSystem17:18分讲解] 联邦 HA....     </span><br>&gt;}<br><br>\<span class="hljs-annotation">@Test</span><br><span class="hljs-keyword">public</span> <span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">uploadFile</span><span class="hljs-params">()</span></span>{<br>    fs.copyFromLocalFile(<span class="hljs-keyword">new</span> Path(<span class="hljs-string">"c:/access.log"</span>), <span class="hljs-keyword">new</span> Path(<span class="hljs-string">"/access.log"</span>));<br>    fs.close() ;<br>}<br></code></pre>

</div><div id="wmd-preview-section-61727" class="wmd-preview-section preview-content">

<h4 id="问题解决本地环境问题空指针与用户权限问题">问题解决（本地环境问题空指针与用户权限问题）</h4>

</div><div id="wmd-preview-section-61728" class="wmd-preview-section preview-content">

<h5 id="发生空指针异常">发生空指针异常</h5>

<p>本地系统 调用shell ，但是本地是没有hadoop的本地库  native…文件夹 <br>
？如何解决？</p>

</div><div id="wmd-preview-section-61729" class="wmd-preview-section preview-content">

<h5 id="windows上配置hadoop环境变量">windows上配置hadoop环境变量</h5>

<p><strong>首先在windows中配置一个HADOOP_HOME</strong>  <br>
path中也要添加</p>

</div><div id="wmd-preview-section-61730" class="wmd-preview-section preview-content">

<h5 id="windows-上编译hadoop-bin目录-lib替换">windows 上编译hadoop bin目录 lib替换</h5>

<p>与本地平台有关，需要替换掉 win7的win7 win10的win10…. <br>
替换俩目录！！</p>

<p>再试 运行成功  <strong>没有拷贝上</strong>！！！！</p>

<p>设置完文件系统后</p>

</div><div id="wmd-preview-section-61731" class="wmd-preview-section preview-content">

<h5 id="权限不足">权限不足</h5>

<p>再试  Permission denied 。。。。 此时权限不足 。 <br>
要么该权限（不建议） 改用户身份(伪装自己的名字 ，hdfs是弱机制的，改windwos的用户名称，很low的……..该环境变量) <br>
jvm 看到环境参数   jconsole jvisualvm 监控  <br>
run configuration 设置 </p>

<blockquote>
  <p>-DHADOOP_USER_NAME=hadoop <br>
  最终成功~</p>
</blockquote>

<p>总结： 客户端操作hdfs时是有个用户身份的，默认情况 hdfs客户端api从jvm中获取一个参数 DHADOOP_USER_NAME 作为文件操作的用户身份，需要设置 为hadoop</p>

<p><strong>还可以 fileSystem.get(new URI(“hdfs://mini1:9000”),conf,”hadoop”)</strong></p>

<p>testDownload(){ <br>
fs.copyToLocalFile(new Path(“/access.log.copy”), new path(“d:/||d:\”)); <br>
fs.close(); <br>
} <br>
//bin目录一定要注意本地环境与hadoop是相关的</p>

<p>本地库 win10 只需要hadoop_home 即可 上传时可以成功的 <br>
下载的时候 copyToLocalFile(…false[不使用本地的，使用java的…..]) //看重载参数</p>

</div><div id="wmd-preview-section-61732" class="wmd-preview-section preview-content"></div><div id="wmd-preview-section-footnotes" class="preview-content"></div></div></body></html>