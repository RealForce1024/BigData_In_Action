<!DOCTYPE html><html><head><title>day09</title><meta charset='utf-8'><link href='https://dn-maxiang.qbox.me/res-min/themes/marxico.css' rel='stylesheet'><style></style></head><body><div id='preview-contents' class='note-content'>
                        <div id="wmd-preview" class="preview-content"></div>
                    <div id="wmd-preview-section-16207" class="wmd-preview-section preview-content">

</div><div id="wmd-preview-section-16208" class="wmd-preview-section preview-content">

<h1 id="day09">day09</h1>

<p></p>

<hr>

<div><div class="toc"><div class="toc">
<ul>
<li><a href="#day09">day09</a><ul>
<li><a href="#个人插播">个人插播</a></li>
<li><a href="#问题回顾">问题回顾</a></li>
<li><a href="#复习">复习</a><ul>
<li><a href="#mr的整体工作机制">mr的整体工作机制</a></li>
<li><a href="#mr的运行流程">mr的运行流程</a></li>
<li><a href="#每个统计结果">每个统计结果</a></li>
</ul>
</li>
<li><a href="#mr的运行细节及-shuffle-combiner">mr的运行细节及 shuffle 、 combiner</a><ul>
<li><a href="#实验">实验</a></li>
</ul>
</li>
<li><a href="#问题">问题</a></li>
<li><a href="#mr-与yarn">mr 与yarn</a></li>
<li><a href="#mr的运行模式">mr的运行模式</a></li>
<li><a href="#代码案例-商品-订单">代码案例  商品 订单</a></li>
</ul>
</li>
</ul>
</div>
</div>
</div>

</div><div id="wmd-preview-section-16209" class="wmd-preview-section preview-content">

<h2 id="个人插播">个人插播</h2>

<ol><li rel="0">windows本地的环境需要编译 目前不需要， <br>
<ol>
<li rel="1">windows版本需要windows sdk库 vs statudio啥的。。实在不行再弄，否则将很蛋疼</li>
<li rel="2">但centos32位的hadoop2.6.4需要找找版本，否则就独自再编译</li></ol></li>
<li rel="1">困扰”小涛”老师eclipse自动插入参数的问题 <br>
可以在eclipse中菜单栏 window选项preferences-java-editor-content assist <br>
将fill method arguments and show gueessed arguments勾选去掉。</li>
<li rel="2">jar -jar 本地运行集群模式（”小涛”老师笔记的补充）</li>
</ol>

<p>今天科比退役，笔记基本没怎么做，请见谅。这周会再整理</p>

</div><div id="wmd-preview-section-16210" class="wmd-preview-section preview-content">

<h2 id="问题回顾">问题回顾</h2>

<p>context.write(null,bean) …. <br>
mr 连接拒绝  环境配置混乱….</p>

</div><div id="wmd-preview-section-16211" class="wmd-preview-section preview-content">

<h2 id="复习">复习</h2>

</div><div id="wmd-preview-section-16212" class="wmd-preview-section preview-content">

<h3 id="mr的整体工作机制">mr的整体工作机制</h3>

<p>由yarn负责启动 map reducer app master <br>
其启动的数量机制？ <br>
map task 按照数据切片由客户端切割 获取文件大小 比较   ，与blocksize不是一个概念无关，hdfs中的概念。</p>

<p>一个reduce可能依靠所有的maptask hashcode%</p>

</div><div id="wmd-preview-section-16213" class="wmd-preview-section preview-content">

<h3 id="mr的运行流程">mr的运行流程</h3>

<p>复习</p>

</div><div id="wmd-preview-section-16214" class="wmd-preview-section preview-content">

<h3 id="每个统计结果">每个统计结果</h3>

<p>reduce 中设置自己的缓存列表 ，进行排序。但如何知道reduce在何时统计完成</p>

<p>treemap  cleanup方法可以（但是数据量大时，内存效率较低，不建议使用）</p>

<p>map会将key作为排序 ，将总流量bean作为key ，实现comparable接口的compareTo方法</p>

<p>bean.set(1,2) <br>
bean.set(10,20) <br>
bean.set(100,200) <br>
list.add(bean) <br>
同一个对象写出的内容因为序列化 值是不同的。</p>

<p>//reduce 反序列化出对象</p>

<p>mr中的key需要排序，所以想自定义 就实现 WritableComparble</p>

<p>注意此时的 reduce要保证为一个，全局的排序结果 </p>

<p>提交jar跑很慢…. <br>
本地提交单机模拟跑 很快…</p>

<hr>

</div><div id="wmd-preview-section-16215" class="wmd-preview-section preview-content">

<h2 id="mr的运行细节及-shuffle-combiner">mr的运行细节及 shuffle 、 combiner</h2>

<p>看图分析理解 <br>
读数据的接口 inputFormat接口  读取 与数据源处理解耦 ，其哟个成员RecordReader <br>
sequenceFileInput  <br>
TextInputFormat</p>

<p>返回 k ,v   （自定义k，v） 交给 自定义的 hadoop（hadoop 中mapper普通类（查看源码，其没做啥事儿））</p>

<p>context.write()  —-&gt;  outputCollector内部 —-&gt; 环形缓冲区(本质数组 byte , 但有很多索引指针 来 解决 写溢出…) 默认size 100m <strong>mr.sort.mb参数可配</strong>  spiller（分区排序 ）调用partioner 默认快排 外排—-&gt; 溢出到文件中  –&gt; 局部有序的文件 归并排序 —-&gt; </p>

<p>下载到reducetask本地磁盘工作目录 需要进行合并的（保证输出的结果是有序的）归并排序   —-&gt; reducer(k,values)  —-&gt; 相同的 使用GroupingComparaor(k,nextkey)[可以按照任意的内容看成是一组，但其默认实现是调用对比的方法] 判断为一组，所以就按照第一个元素的key作为reduce(k,values)</p>

<p>–&gt; 提高效率 combiner 向外溢出 （自定义逻辑 ： 将相同的key的累加  ） <br>
–&gt; 合并的时候 还可以在combiner一次。。。。（类似reduce的逻辑，不过是针对自己maptask结果进行汇聚，reducer是全局性的汇总）</p>

<p>extends reducer&lt;……&gt;   溢出 合并的时候都会调用该组件 <br>
注意：combiner 使用场合 不要影响后面的业务逻辑  慎用…  </p>

<p>很多小的文件  交给一个maptask 那效率很低的 <br>
如何优化 ？  <br>
关于大量小文件的优化策略： <br>
（1）默认情况下，textInputFormat对任务的切片机制是按文件规划切后排，不管文件多小，都会是一个单独的切片，都叫给一个maptask，。如果大量小文件，就会产生大量的maptask，处理效率及其低下。</p>

<p>（2） 数据处理的最前端（预处理、采集），将小文件合并为大文件再上传到hdfs中再后续分析 <br>
（3）补救措施：如果已经有很多大量小文件在hdfs中，可以使用另一个InputFormat来做切片，使用combineFileInputFormat，它的切片逻辑与fileINputFormat不同：他可以将多个小文件从逻辑上规划到一个切片中，这样，多个小文件就可以交给一个maptask</p>

</div><div id="wmd-preview-section-16216" class="wmd-preview-section preview-content">

<h3 id="实验">实验</h3>

<p>wordcount 替换textinputformat 为 combinefileinput   maptask与cpu核数一致  切片也默认为128m  与blocksize一致 也是效率较好</p>

<p>在本地运行 <br>
run configuration   本地磁盘  <br>
使用线程  模拟进程 伪分布式 <br>
细节 getSplits  关键点  机架 通信io等等细节</p>

<p>blocksize <br>
一个文件是一个block  <br>
2m 2m </p>

</div><div id="wmd-preview-section-16217" class="wmd-preview-section preview-content">

<h2 id="问题">问题</h2>

<p>combinefile的切片大小 看源码 里面的逻辑 不会超过最大值</p>

</div><div id="wmd-preview-section-16218" class="wmd-preview-section preview-content">

<h2 id="mr-与yarn">mr 与yarn</h2>

<p>画图解析 <br>
yarn ： 资源调度系统 （运算资源：jar包、config，cpu/内存、io（未分开）） <br>
利用linux cgroup 资源隔离机制 （cpu时间片 底层 等 ）  docker openstack（管理虚拟容器的框架，在docker之上，但他们自己实现的类似docker） <br>
resource manager <br>
nodemanager nodemanager </p>

<p>container </p>

<p>job.submit()  —&gt; yarnRunner impl clientProtocol —&gt;(resource manager)</p>

<p>返回 提交路径 及jobid</p>

<p>调度策略  基本的Fifo 队列 得等待 （老版本默认） <br>
fair <br>
capacity 公平调度 （新版本默认） <br>
自己拓展细节</p>

<p>老大会检测，如果有慢的，会再申请，最终看两者先完成的结果。</p>

<p>yarn只负责程序运行所需要的资源的分配与回收等调度任务 <br>
与程序内部运作机制完全无关 <br>
yarn与mr解耦 ，所以yarn是个通用的平台，spark也可以在其上运行。</p>

<p>hadoop1 中并无yarn的概念。 那mr如何拿到的资源？ <br>
jobTracker taskTracker</p>

<hr>

</div><div id="wmd-preview-section-16219" class="wmd-preview-section preview-content">

<h2 id="mr的运行模式">mr的运行模式</h2>

<p>本地运行与hdfs <br>
conf.set (mapreduce.framework.name,”local”); <br>
conf.set(“fs.defaultFs”,”file:///”) <br>
localjobrunner <br>
submit joblocal。。。。。</p>

<p>建议就在本地上跑 </p>

<p><strong>jar -jar 运行集群模式</strong> 笔记补充</p>

<p>yarnrunner 中修改 <br>
windows跑远程yarn集群  修改源码 中的windows中产生的相关内容 ，以适应linux环境</p>

<p>配置参数 指定jar 修改yarnRunner源码</p>

<p>$hadoop_Home/logs/userlogs/….</p>

<p>尽量能在uninx 上写程序 就没啥环境困扰了。</p>

</div><div id="wmd-preview-section-16220" class="wmd-preview-section preview-content">

<h2 id="代码案例-商品-订单">代码案例  商品 订单</h2>

<p><strong>将特定条件 分组 发送到reduce中 解决mr的关键</strong></p>

<p>map -&gt;切片 -&gt; 文件   context  <br>
context.getInputSplit();</p>

<p>代码</p>

<p>eclipse hdfs插件</p>

<p>代码自己要写实现写一遍。</p>

</div><div id="wmd-preview-section-16221" class="wmd-preview-section preview-content"></div><div id="wmd-preview-section-footnotes" class="preview-content"></div></div></body></html>